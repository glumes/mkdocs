---
title: "音视频编解码的那些基础理论"
subtitle: ""
date: 2017-12-22T16:03:10+08:00
categories: ["FFmpeg"]
tags: ["FFmpeg"]
 
toc: true
original: true
addwechat: true
slug: "encode-and-decode-summary"
---



最近在研究学习 FFmpeg，从网上参考了好多资料，其中最了不起的就当属——[雷霄骅](http://blog.csdn.net/leixiaohua1020)大神了，若没有他的博文，别说入门了，可能连门在哪里都不知道，在此还是要表达一下对雷神的敬佩和敬仰。

本文主要讲的是视频文件的解码，从视频文件的封装格式解码到原始数据格式，通过讲解涉及到的各种概念，从而理清整个思路和流程。

<!--more-->

## 为何封装格式？

在我们平时接触到的视频文件，大都是以`.mp4`、`.flv`、`.avi`、`.rmvb`后缀结尾的。

然而，事情并不是这么简单，这些后缀名其实还代表着一种封装格式，一种把音频数据和视频数据打包成一个文件的格式规范。

配图一张，以 `.xxx` 后缀的视频文件大概包含如下内容：

![http://7xqe3m.com1.z0.glb.clouddn.com/blog_video_file_container.png](http://7xqe3m.com1.z0.glb.clouddn.com/blog_video_file_container.png)

由此可见，我们平时接触的`.avi`包含的东西还是挺多的。

## 封装格式的编解码

在上面有讲到，视频文件其实包含着音频数据和视频数据，那么这些音频数据和视频数据又是如何形成封装格式的呢？

这里就涉及到编解码的知识了，原始的音频或者视频数据是很大的。比如，如果不进行压缩或者编码处理，用手机随便录一段视频可能就有几百M了，而有时候看部一个小时的电影也就才几百M，这就是对原始数据处理方式不同的结果。

而我们的音频或者视频数据，也是要通过`编码`处理进行压缩，对他们进行编码处理后，体积都会变小，这样才能合并成具体的某种封装格式。

同时，当我们要播放视频或者音频时，还需要对编码压缩后的数据进行`解码`，从压缩的数据解码到原始数据，并将原始数据送到对应的设备，比如显卡或者声卡进行播放。这就是一个`解封装`的过程。

不同的封装格式支持的音视频编解码标准不一样，越是优越的封装格式，支持的编码标准越多，比如：`MKV`封装格式，而`RMVB`封装格式就算落后的，支持的音视频标准有限。

这里，还是借雷神的图一张，很形象的解释了音频文件解码的整个过程。

*	解协议->封装格式数据
*	解封装->音频数据和视频数据
	*	音频解码->设备输出
	*	视频解码->设备输出

![http://img.blog.csdn.net/20160117235313221](http://img.blog.csdn.net/20160117235313221)

## 音视频的原始数据格式和编解码标准

在上面有讲到，封装格式其实就是音频或者视频的原始数据进行编码压缩得到的。而且，音频和视频对应的原始数据格式和编解码标准都不一样。

### 音频的原始数据格式和编解码标准

音频的原始数据格式主要有如下几种：

*	PCM 格式

音频的编解码标准主要有如下几种：

*	MP3 
*	AAC
*	AC-3

### 视频的原始数据格式和编解码标准

视频的原始数据格式主要有如下几种：

*	YUV 格式
*	RGB 格式

视频的编解码标准主要有如下几种：

*	H.264
*	H.265
*	MPEG2

这些原始数据格式和编解码标准初次看是有点陌生，但接触多了，也就逐渐熟悉了，先以掌握主流的编解码标准为主，这里也只是列出了其中一部分而已。

## MEPG->PCM 的解析

有了以上的理论基础，就可以开始我们的解析工作了。

使用 FFmpeg 3.x 的版本（与 2.x 版本相比接口有了较大变化）将 MEPG 的视频文件解码到 PCM 的原生数据格式。

这里的案例参考的是 FFmpeg 官网的例子，地址在此：[http://ffmpeg.org/doxygen/trunk/examples.html](http://ffmpeg.org/doxygen/trunk/examples.html)。



## 参考
1. http://blog.csdn.net/leixiaohua1020/article/details/15811977
2. http://ffmpeg.org/doxygen/trunk/examples.html


